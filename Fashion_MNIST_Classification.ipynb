{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion-MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDFSBD7ZsTEI"
      },
      "source": [
        "# Classification of the Fashion MNIST Dataset using Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJClStJdst7b"
      },
      "source": [
        "Import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3WyeZLUsEwo"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "from tensorflow import keras\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igWQrsZPtIVN"
      },
      "source": [
        "Load the Fashion MNIST Dataset from the datasets API in keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-AU7T17s3jY"
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0iTSocwtYwu"
      },
      "source": [
        "Load the training and test images and labels to separate variables using `load_data` method inside the `mnist` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBFvFojctT9l",
        "outputId": "d0370ed8-5e94-49a6-e1ba-9f67acd6d707"
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvhin6o-yz4K"
      },
      "source": [
        "We normalize the training images and test images as it's better for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etigkGxeyylK"
      },
      "source": [
        "training_images = training_images/255.0\r\n",
        "test_images = test_images/255.0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBj4lzcovchp"
      },
      "source": [
        "Buid a simple neural network model consists of (Flatten --> ReLU(128) --> ReLU(256) --> Softmax(10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO_C9LcRtWZz"
      },
      "source": [
        "model = tf.keras.models.Sequential([\r\n",
        "  tf.keras.layers.Flatten(),\r\n",
        "  tf.keras.layers.Dense(units=128, activation=tf.nn.relu),\r\n",
        "  tf.keras.layers.Dense(units=10, activation=tf.nn.softmax)\r\n",
        "])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guVx226Ow5ef"
      },
      "source": [
        "Compile the model using ADAM as an optimizer and categorical crossentropy as the loss function. We also add accuracy in our metrics parameter to track during the fitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RaO_XIww2RU"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxYdtN56yK0v"
      },
      "source": [
        "We fit the training images (features-X) and training labels (output-y) in 5 epochs with batch size of 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsXdTJKcyD9G",
        "outputId": "0c82da09-c57f-4e4d-baff-a8973db9956b"
      },
      "source": [
        "model.fit(training_images, training_labels, epochs=20, batch_size=32)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6240 - accuracy: 0.7865\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3826 - accuracy: 0.8612\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3368 - accuracy: 0.8754\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3121 - accuracy: 0.8848\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2876 - accuracy: 0.8925\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2775 - accuracy: 0.8978\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2634 - accuracy: 0.9035\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2559 - accuracy: 0.9048\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2453 - accuracy: 0.9071\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2333 - accuracy: 0.9137\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2254 - accuracy: 0.9145\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2193 - accuracy: 0.9175\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2116 - accuracy: 0.9222\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2047 - accuracy: 0.9240\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2036 - accuracy: 0.9223\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1951 - accuracy: 0.9253\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1888 - accuracy: 0.9292\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1850 - accuracy: 0.9307\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1793 - accuracy: 0.9322\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1755 - accuracy: 0.9329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f67e77ace48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2D9GG6l1paS"
      },
      "source": [
        "We evaluate the model on our test images and test labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MI4D-NxyYiz",
        "outputId": "f45985a8-0f0c-4add-e1b8-20202b6b4795"
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3601936399936676, 0.8863000273704529]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHY2rKus5ssa"
      },
      "source": [
        "We reach an accuracy on the training set of 93% and on the test set 87%"
      ]
    }
  ]
}